{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from csv import writer\n",
    "import json\n",
    "import geojson\n",
    "import geopandas as gpd\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for the features we interested in\n",
    "parent_dir = \"../data/raw/interested_facilities\"\n",
    "os.makedirs(parent_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\n",
    "    'https://services6.arcgis.com/GB33F62SbDxJjwEL/ArcGIS/rest/services/Vicmap_Features_of_Interest/FeatureServer/8/query?where=FEATURE_CODE+%3D+%27PARK%27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=standard&distance=0.0&units=esriSRUnit_Meter&relationParam=&returnGeodetic=false&outFields=&returnGeometry=true&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=REGISTRATION_DATE&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnTrueCurves=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=',\n",
    "    'https://services6.arcgis.com/GB33F62SbDxJjwEL/ArcGIS/rest/services/Vicmap_Features_of_Interest/FeatureServer/8/query?where=FEATURE_CODE+%3D+%27PRSC%27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=standard&distance=0.0&units=esriSRUnit_Meter&relationParam=&returnGeodetic=false&outFields=&returnGeometry=true&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=REGISTRATION_DATE&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnTrueCurves=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=',\n",
    "    'https://services6.arcgis.com/GB33F62SbDxJjwEL/ArcGIS/rest/services/Vicmap_Features_of_Interest/FeatureServer/8/query?where=FEATURE_CODE+%3D+%27SESC%27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=standard&distance=0.0&units=esriSRUnit_Meter&relationParam=&returnGeodetic=false&outFields=&returnGeometry=true&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=REGISTRATION_DATE&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnTrueCurves=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=',\n",
    "    'https://services6.arcgis.com/GB33F62SbDxJjwEL/ArcGIS/rest/services/Vicmap_Features_of_Interest/FeatureServer/8/query?where=FEATURE_CODE+%3D+%27UNIV%27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=standard&distance=0.0&units=esriSRUnit_Meter&relationParam=&returnGeodetic=false&outFields=&returnGeometry=true&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=REGISTRATION_DATE&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnTrueCurves=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=',\n",
    "    'https://services6.arcgis.com/GB33F62SbDxJjwEL/ArcGIS/rest/services/Vicmap_Features_of_Interest/FeatureServer/8/query?where=FEATURE_CODE+%3D+%27SHCE%27&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=standard&distance=0.0&units=esriSRUnit_Meter&relationParam=&returnGeodetic=false&outFields=&returnGeometry=true&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&defaultSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=REGISTRATION_DATE&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnTrueCurves=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=',\n",
    "]\n",
    "name_list = ['park', 'primary_school', 'secondary_school', 'university', 'shopping_mall',]\n",
    "\n",
    "def fetch_and_write_data(url, file_name):\n",
    "    response = requests.get(url)\n",
    "    content = response.json()\n",
    "\n",
    "    file_path = os.path.join(parent_dir, file_name)\n",
    "    \n",
    "    with open(file_path, 'w', newline='') as g:\n",
    "        thewriter = writer(g)\n",
    "        thewriter.writerow(['name', 'longitude', 'latitude'])\n",
    "        \n",
    "        for feature in content['features']:\n",
    "            place_name = feature['properties']['PLACE_NAME']\n",
    "            longitude, latitude = feature['geometry']['coordinates']\n",
    "            thewriter.writerow([place_name, longitude, latitude])\n",
    "\n",
    "for url, name in zip(url_list, name_list):\n",
    "    fetch_and_write_data(url, f'{name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/hotosm_aus_health_facilities_points_geojson.geojson', 'r', encoding='utf-8') as f:\n",
    "    data = geojson.load(f)\n",
    "\n",
    "with open('../data/raw/interested_facilities/hospital.csv', 'w', encoding='utf-8', newline='') as csvfile:\n",
    "    fieldnames = ['name', 'longitude', 'latitude']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for feature in data['features']:\n",
    "\n",
    "        name = feature['properties'].get('name')\n",
    "        longitude = feature['geometry']['coordinates'][0]\n",
    "        latitude = feature['geometry']['coordinates'][1]\n",
    "\n",
    "        writer.writerow({'name': name, 'longitude': longitude, 'latitude': latitude})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the postcode and the suburb name to the facilities that we interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the hospital dataset, delete the empty or NaN name raws\n",
    "hospital_data = pd.read_csv('../data/raw/interested_facilities/hospital.csv')\n",
    "\n",
    "# Clean rows where 'name' is empty or NaN\n",
    "hospital_data_cleaned = hospital_data.dropna(subset=['name'])\n",
    "\n",
    "# Save the cleaned dataset\n",
    "hospital_data_cleaned.to_csv('../data/raw/interested_facilities/hospital_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df = pd.read_csv(\"../data/raw/interested_facilities/hospital_clean.csv\")\n",
    "park_df = pd.read_csv(\"../data/raw/interested_facilities/park.csv\")\n",
    "primary_df = pd.read_csv(\"../data/raw/interested_facilities/primary_school.csv\")\n",
    "secondary_df = pd.read_csv(\"../data/raw/interested_facilities/secondary_school.csv\")\n",
    "shoppingmall_df = pd.read_csv(\"../data/raw/interested_facilities/shopping_mall.csv\")\n",
    "university_df = pd.read_csv(\"../data/raw/interested_facilities/university.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished batch 1, wait 60 seconds to continue...\n",
      "finished batch 2, wait 60 seconds to continue...\n",
      "finished batch 3, wait 60 seconds to continue...\n",
      "finished batch 4, wait 60 seconds to continue...\n",
      "finished batch 5, wait 60 seconds to continue...\n",
      "finished batch 6, wait 60 seconds to continue...\n",
      "finished batch 7, wait 60 seconds to continue...\n",
      "finished batch 8, wait 60 seconds to continue...\n",
      "finished batch 9, wait 60 seconds to continue...\n"
     ]
    }
   ],
   "source": [
    "api_key = \"\" #To prevent exposure or unknown use has been hidden, please contact Xiaowei Guo to get the key\n",
    "\n",
    "# #because the daily limited API usage, do not run all the facilities at one time\n",
    "os.makedirs(\"../data/raw/intermediate_results\", exist_ok=True)\n",
    "\n",
    "\n",
    "# get postcode and suburb name by latitude and longitude\n",
    "def get_postcode_suburb(latitude, longitude):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/geocode/json?latlng={latitude},{longitude}&key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'results' in data and len(data['results']) > 0:\n",
    "            address_components = data['results'][0]['address_components']\n",
    "            postcode = None\n",
    "            suburb = None\n",
    "            for component in address_components:\n",
    "                if 'postal_code' in component['types']:\n",
    "                    postcode = component['long_name']\n",
    "                if 'locality' in component['types']:\n",
    "                    suburb = component['long_name']\n",
    "            return postcode, suburb\n",
    "    return None, None\n",
    "\n",
    "# Add postcode and suburb columns to each dataset and process in batches\n",
    "def add_postcode_suburb_in_batches(df, batch_size=500, delay=60):\n",
    "    df['postcode'] = ''\n",
    "    df['suburb'] = ''\n",
    "    \n",
    "    for start in range(0, len(df), batch_size):\n",
    "        batch_df = df[start:start+batch_size]\n",
    "        for index, row in batch_df.iterrows():\n",
    "            latitude = row['latitude']\n",
    "            longitude = row['longitude']\n",
    "            postcode, suburb = get_postcode_suburb(latitude, longitude)\n",
    "            df.at[index, 'postcode'] = postcode\n",
    "            df.at[index, 'suburb'] = suburb\n",
    "        # Save the progress of each batch\n",
    "        df.to_csv(f\"../data/raw/intermediate_results/intermediate_result_{start // batch_size}.csv\", index=False)\n",
    "        print(f\"finished batch {start // batch_size + 1}, wait {delay} seconds to continue...\")\n",
    "        time.sleep(delay)  # wait between batches\n",
    "\n",
    "    return df\n",
    "\n",
    "# batch each dataset\n",
    "batch_size = 500  # Process 500 rows per batch\n",
    "delay_between_batches = 60  # Wait 60s between each batch\n",
    "\n",
    "hospital_df = add_postcode_suburb_in_batches(hospital_df, batch_size, delay_between_batches)\n",
    "park_df = add_postcode_suburb_in_batches(park_df, batch_size, delay_between_batches)\n",
    "primary_df = add_postcode_suburb_in_batches(primary_df, batch_size, delay_between_batches)\n",
    "secondary_df = add_postcode_suburb_in_batches(secondary_df, batch_size, delay_between_batches)\n",
    "shoppingmall_df = add_postcode_suburb_in_batches(shoppingmall_df, batch_size, delay_between_batches)\n",
    "university_df = add_postcode_suburb_in_batches(university_df, batch_size, delay_between_batches)\n",
    "\n",
    "# save the updated dataset\n",
    "park_df.to_csv(\"../data/curated/Facilities/park.csv\", index=False)\n",
    "primary_df.to_csv(\"../data/curated/Facilities/primary_school.csv\", index=False)\n",
    "secondary_df.to_csv(\"../data/curated/Facilities/secondary_school.csv\", index=False)\n",
    "shoppingmall_df.to_csv(\"../data/curated/Facilities/shopping_mall.csv\", index=False)\n",
    "university_df.to_csv(\"../data/curated/Facilities/university.csv\", index=False)\n",
    "hospital_df.to_csv(\"../data/curated/Facilities/hospital.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/curated/Facilities/hospital.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "postcode_column = 'postcode'\n",
    "\n",
    "df[postcode_column].fillna(0, inplace=True)\n",
    "\n",
    "df[postcode_column] = df[postcode_column].astype(int)\n",
    "\n",
    "postcode_count = df.groupby(postcode_column).size().reset_index(name='count')\n",
    "\n",
    "output_path = '../data/curated/postcode_hospital_count.csv'\n",
    "postcode_count.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_file = '../data/curated/postcode_hospital_count.csv'\n",
    "property_file = '../data/curated/all_Facilities_min_distance.csv'\n",
    "\n",
    "hospital_df = pd.read_csv(hospital_file)\n",
    "property_df = pd.read_csv(property_file)\n",
    "\n",
    "hospital_df.rename(columns={'postcode': 'addressPostcode'}, inplace=True)\n",
    "hospital_df.rename(columns={'count': 'medical_institution_count'}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(property_df, hospital_df, on='addressPostcode', how='left')\n",
    "\n",
    "merged_df['medical_institution_count'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "output_path = '../data/curated/Final_property_with_features.csv'\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
